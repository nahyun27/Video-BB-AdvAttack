{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in /home/seclab_nahyun/anaconda3/envs/workspace/lib/python3.10/site-packages (4.39.3)\n",
      "Collecting datasets\n",
      "  Obtaining dependency information for datasets from https://files.pythonhosted.org/packages/95/fc/661a7f06e8b7d48fcbd3f55423b7ff1ac3ce59526f146fda87a1e1788ee4/datasets-2.18.0-py3-none-any.whl.metadata\n",
      "  Downloading datasets-2.18.0-py3-none-any.whl.metadata (20 kB)\n",
      "Requirement already satisfied: filelock in /home/seclab_nahyun/anaconda3/envs/workspace/lib/python3.10/site-packages (from transformers) (3.12.3)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.19.3 in /home/seclab_nahyun/anaconda3/envs/workspace/lib/python3.10/site-packages (from transformers) (0.22.2)\n",
      "Requirement already satisfied: numpy>=1.17 in /home/seclab_nahyun/anaconda3/envs/workspace/lib/python3.10/site-packages (from transformers) (1.23.1)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/seclab_nahyun/anaconda3/envs/workspace/lib/python3.10/site-packages (from transformers) (23.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /home/seclab_nahyun/anaconda3/envs/workspace/lib/python3.10/site-packages (from transformers) (6.0.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /home/seclab_nahyun/anaconda3/envs/workspace/lib/python3.10/site-packages (from transformers) (2023.12.25)\n",
      "Requirement already satisfied: requests in /home/seclab_nahyun/anaconda3/envs/workspace/lib/python3.10/site-packages (from transformers) (2.31.0)\n",
      "Requirement already satisfied: tokenizers<0.19,>=0.14 in /home/seclab_nahyun/anaconda3/envs/workspace/lib/python3.10/site-packages (from transformers) (0.15.2)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /home/seclab_nahyun/anaconda3/envs/workspace/lib/python3.10/site-packages (from transformers) (0.4.2)\n",
      "Requirement already satisfied: tqdm>=4.27 in /home/seclab_nahyun/anaconda3/envs/workspace/lib/python3.10/site-packages (from transformers) (4.66.1)\n",
      "Collecting pyarrow>=12.0.0 (from datasets)\n",
      "  Obtaining dependency information for pyarrow>=12.0.0 from https://files.pythonhosted.org/packages/01/e0/13aada7b0af1039554e675bd8c878acb3d86bab690e5a6b05fc8547a9cf2/pyarrow-15.0.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata\n",
      "  Downloading pyarrow-15.0.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.0 kB)\n",
      "Collecting pyarrow-hotfix (from datasets)\n",
      "  Obtaining dependency information for pyarrow-hotfix from https://files.pythonhosted.org/packages/e4/f4/9ec2222f5f5f8ea04f66f184caafd991a39c8782e31f5b0266f101cb68ca/pyarrow_hotfix-0.6-py3-none-any.whl.metadata\n",
      "  Downloading pyarrow_hotfix-0.6-py3-none-any.whl.metadata (3.6 kB)\n",
      "Collecting dill<0.3.9,>=0.3.0 (from datasets)\n",
      "  Obtaining dependency information for dill<0.3.9,>=0.3.0 from https://files.pythonhosted.org/packages/c9/7a/cef76fd8438a42f96db64ddaa85280485a9c395e7df3db8158cfec1eee34/dill-0.3.8-py3-none-any.whl.metadata\n",
      "  Downloading dill-0.3.8-py3-none-any.whl.metadata (10 kB)\n",
      "Requirement already satisfied: pandas in /home/seclab_nahyun/anaconda3/envs/workspace/lib/python3.10/site-packages (from datasets) (2.1.0)\n",
      "Collecting xxhash (from datasets)\n",
      "  Obtaining dependency information for xxhash from https://files.pythonhosted.org/packages/80/8a/1dd41557883b6196f8f092011a5c1f72d4d44cf36d7b67d4a5efe3127949/xxhash-3.4.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata\n",
      "  Downloading xxhash-3.4.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
      "Collecting multiprocess (from datasets)\n",
      "  Obtaining dependency information for multiprocess from https://files.pythonhosted.org/packages/bc/f7/7ec7fddc92e50714ea3745631f79bd9c96424cb2702632521028e57d3a36/multiprocess-0.70.16-py310-none-any.whl.metadata\n",
      "  Downloading multiprocess-0.70.16-py310-none-any.whl.metadata (7.2 kB)\n",
      "Collecting fsspec[http]<=2024.2.0,>=2023.1.0 (from datasets)\n",
      "  Obtaining dependency information for fsspec[http]<=2024.2.0,>=2023.1.0 from https://files.pythonhosted.org/packages/ad/30/2281c062222dc39328843bd1ddd30ff3005ef8e30b2fd09c4d2792766061/fsspec-2024.2.0-py3-none-any.whl.metadata\n",
      "  Downloading fsspec-2024.2.0-py3-none-any.whl.metadata (6.8 kB)\n",
      "Collecting aiohttp (from datasets)\n",
      "  Obtaining dependency information for aiohttp from https://files.pythonhosted.org/packages/91/8f/b1f46ef89273414735e5f8835918da305e43857086b70ff11fd89ff3f6f8/aiohttp-3.9.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata\n",
      "  Downloading aiohttp-3.9.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (7.5 kB)\n",
      "Collecting aiosignal>=1.1.2 (from aiohttp->datasets)\n",
      "  Obtaining dependency information for aiosignal>=1.1.2 from https://files.pythonhosted.org/packages/76/ac/a7305707cb852b7e16ff80eaf5692309bde30e2b1100a1fcacdc8f731d97/aiosignal-1.3.1-py3-none-any.whl.metadata\n",
      "  Downloading aiosignal-1.3.1-py3-none-any.whl.metadata (4.0 kB)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /home/seclab_nahyun/anaconda3/envs/workspace/lib/python3.10/site-packages (from aiohttp->datasets) (23.1.0)\n",
      "Collecting frozenlist>=1.1.1 (from aiohttp->datasets)\n",
      "  Obtaining dependency information for frozenlist>=1.1.1 from https://files.pythonhosted.org/packages/ec/25/0c87df2e53c0c5d90f7517ca0ff7aca78d050a8ec4d32c4278e8c0e52e51/frozenlist-1.4.1-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata\n",
      "  Downloading frozenlist-1.4.1-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
      "Collecting multidict<7.0,>=4.5 (from aiohttp->datasets)\n",
      "  Obtaining dependency information for multidict<7.0,>=4.5 from https://files.pythonhosted.org/packages/33/62/2c9085e571318d51212a6914566fe41dd0e33d7f268f7e2f23dcd3f06c56/multidict-6.0.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata\n",
      "  Downloading multidict-6.0.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.2 kB)\n",
      "Collecting yarl<2.0,>=1.0 (from aiohttp->datasets)\n",
      "  Obtaining dependency information for yarl<2.0,>=1.0 from https://files.pythonhosted.org/packages/c3/a0/0ade1409d184cbc9e85acd403a386a7c0563b92ff0f26d138ff9e86e48b4/yarl-1.9.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata\n",
      "  Downloading yarl-1.9.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (31 kB)\n",
      "Collecting async-timeout<5.0,>=4.0 (from aiohttp->datasets)\n",
      "  Obtaining dependency information for async-timeout<5.0,>=4.0 from https://files.pythonhosted.org/packages/a7/fa/e01228c2938de91d47b307831c62ab9e4001e747789d0b05baf779a6488c/async_timeout-4.0.3-py3-none-any.whl.metadata\n",
      "  Downloading async_timeout-4.0.3-py3-none-any.whl.metadata (4.2 kB)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /home/seclab_nahyun/anaconda3/envs/workspace/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.19.3->transformers) (4.7.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/seclab_nahyun/anaconda3/envs/workspace/lib/python3.10/site-packages (from requests->transformers) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/seclab_nahyun/anaconda3/envs/workspace/lib/python3.10/site-packages (from requests->transformers) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/seclab_nahyun/anaconda3/envs/workspace/lib/python3.10/site-packages (from requests->transformers) (1.26.14)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/seclab_nahyun/anaconda3/envs/workspace/lib/python3.10/site-packages (from requests->transformers) (2024.2.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /home/seclab_nahyun/anaconda3/envs/workspace/lib/python3.10/site-packages (from pandas->datasets) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/seclab_nahyun/anaconda3/envs/workspace/lib/python3.10/site-packages (from pandas->datasets) (2023.3.post1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /home/seclab_nahyun/anaconda3/envs/workspace/lib/python3.10/site-packages (from pandas->datasets) (2023.3)\n",
      "Requirement already satisfied: six>=1.5 in /home/seclab_nahyun/anaconda3/envs/workspace/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading datasets-2.18.0-py3-none-any.whl (510 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m510.5/510.5 kB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading dill-0.3.8-py3-none-any.whl (116 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m11.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading aiohttp-3.9.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m8.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading pyarrow-15.0.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (38.4 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m38.4/38.4 MB\u001b[0m \u001b[31m9.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading multiprocess-0.70.16-py310-none-any.whl (134 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m11.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading pyarrow_hotfix-0.6-py3-none-any.whl (7.9 kB)\n",
      "Downloading xxhash-3.4.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.1/194.1 kB\u001b[0m \u001b[31m11.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading aiosignal-1.3.1-py3-none-any.whl (7.6 kB)\n",
      "Downloading async_timeout-4.0.3-py3-none-any.whl (5.7 kB)\n",
      "Downloading frozenlist-1.4.1-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (239 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m239.5/239.5 kB\u001b[0m \u001b[31m11.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading fsspec-2024.2.0-py3-none-any.whl (170 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m170.9/170.9 kB\u001b[0m \u001b[31m11.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading multidict-6.0.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (124 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m124.3/124.3 kB\u001b[0m \u001b[31m10.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading yarl-1.9.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (301 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m301.6/301.6 kB\u001b[0m \u001b[31m8.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: xxhash, pyarrow-hotfix, pyarrow, multidict, fsspec, frozenlist, dill, async-timeout, yarl, multiprocess, aiosignal, aiohttp, datasets\n",
      "  Attempting uninstall: fsspec\n",
      "    Found existing installation: fsspec 2024.3.1\n",
      "    Uninstalling fsspec-2024.3.1:\n",
      "      Successfully uninstalled fsspec-2024.3.1\n",
      "Successfully installed aiohttp-3.9.4 aiosignal-1.3.1 async-timeout-4.0.3 datasets-2.18.0 dill-0.3.8 frozenlist-1.4.1 fsspec-2024.2.0 multidict-6.0.5 multiprocess-0.70.16 pyarrow-15.0.2 pyarrow-hotfix-0.6 xxhash-3.4.1 yarl-1.9.4\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install transformers datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "# 0번 gpu 만을 사용하고 싶은 경우\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 1: Translate the Provided Prompt to Korean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Text 1: \n",
      "Translate to Korean: A large language model (LLM) is a language model notable for its ability to achieve general-purpose language generation and other natural language processing tasks such as classification. Several types of LLMs are available: a language learning model, a program-based implementation of a language of general interest (NLP), and a program-level inference library. However, they all are usually constructed as language representations with minimal effort [30]. Furthermore, many of the language modeling frameworks available provide\n",
      "\n",
      "Generated Text 2: \n",
      "Translate to Korean: A large language model (LLM) is a language model notable for its ability to achieve general-purpose language generation and other natural language processing tasks such as classification. Using LLMs can perform language-related tasks such as language categorization, speech recognition, etc. By leveraging a common mechanism of the language model, it is possible to perform language semantic tasks without affecting the correctness in the model. The problem with using single-point models such as ML, is that they are\n",
      "\n",
      "Generated Text 3: \n",
      "Translate to Korean: A large language model (LLM) is a language model notable for its ability to achieve general-purpose language generation and other natural language processing tasks such as classification. This is accomplished by two important steps: Using a system of three or more languages of varying complexity and complexity by using a simple language model to represent each language in a set language structure. Using multiple languages to represent each language by adding a new language and translating from one language to another. Thus, each language is\n",
      "\n",
      "Generated Text 4: \n",
      "Translate to Korean: A large language model (LLM) is a language model notable for its ability to achieve general-purpose language generation and other natural language processing tasks such as classification. In this model, the two major processes of translation are inextricably connected. The languages are defined under the model by three primary components: syntax (an element of structure that describes a sentence as \"true\"), syntax data (which is the source of information about the sentence or sentence structure) and grammatical\n",
      "\n",
      "Generated Text 5: \n",
      "Translate to Korean: A large language model (LLM) is a language model notable for its ability to achieve general-purpose language generation and other natural language processing tasks such as classification. Many features of it are also available in all languages. There are several basic features such as high level of familiarity in coding the code, and familiarity with Korean.\n",
      "\n",
      "In practice, this language learning system can be used as a good guide for languages such as Korean.\n",
      "\n",
      "How does the Language Learning System\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline, set_seed\n",
    "\n",
    "generator = pipeline('text-generation', model='gpt2')\n",
    "set_seed(44)\n",
    "prompt = \"Translate to Korean: A large language model (LLM) is a language model notable for its ability to achieve general-purpose language generation and other natural language processing tasks such as classification.\"\n",
    "results = generator(prompt, max_length=100, truncation=True, num_return_sequences=5, pad_token_id=50256)\n",
    "\n",
    "\n",
    "for i, result in enumerate(results):\n",
    "    print(f\"Generated Text {i+1}: \\n{result['generated_text']}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 2: Execute an Example from a Paper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q&A 1: \n",
      "Who wrote the book the origin of species?\n",
      "\n",
      "\"This really is about what comes out of my mind through reading, not what I think about reading as I know it. My understanding becomes less and less of what's right and less and less\n",
      "\n",
      "Q&A 2: \n",
      "Who is the founder of the ubuntu project?\n",
      "\n",
      "Why are they doing this? The ubuntu project is a web-based operating system and we provide open source software and documentation for the program. This is why Ubuntu users need to work in\n",
      "\n",
      "Q&A 3: \n",
      "Who is the quarterback for the green bay packers? He plays in the blue line with Jim Harbaugh. He's the red-shirt sophomore, a redshirt junior, and of course, he's the coordinator at the team's new headquarters - but\n",
      "\n",
      "Q&A 4: \n",
      "Panda is a national animal of which country?\n",
      "\n",
      "No. It is an animal of which species? It's an animal of which species?\n",
      "\n",
      "Do you know which animals can be thought of as national?\n",
      "\n",
      "Yes. We have\n",
      "\n",
      "Q&A 5: \n",
      "Who came up with the theory of relativity? (Don't get me wrong; it's simple.) It's all one of those stories that I'm not sure I have much of to say—because I think it's all going to make me seem\n",
      "\n",
      "Q&A 6: \n",
      "When was the first star wars film released? I knew I was in good hands when the film came out but I still couldn't get any closer to making a Star Wars movie than I was back when I was making the original film. So I thought\n",
      "\n",
      "Q&A 7: \n",
      "What is the most common blood type in Sweden?\n",
      "\n",
      "Mixed Blood Type: Usually two blood types.\n",
      "\n",
      "This type differs from blood type A in that it is a non-human body type.\n",
      "\n",
      "It has a much narrower red\n",
      "\n",
      "Q&A 8: \n",
      "Who is regarded as the founder of psychoanalysis?\n",
      "\n",
      "We have no knowledge of Freud.\n",
      "\n",
      "Has Freud been a psychoanalyst?\n",
      "\n",
      "No. He was not a psychoanalyst. The only person in his position who could be\n",
      "\n",
      "Q&A 9: \n",
      "Who took the first steps on the moon in 1969?\n",
      "\n",
      "A lot of people have been waiting for this kind of reaction, to say the least. It was one of the most amazing and thrilling, very exciting stories I've heard in ages.\n",
      "\n",
      "Q&A 10: \n",
      "Who is the largest supermarket chain in the uk?\n",
      "\n",
      "What are your biggest disappointments from your time in the business?\n",
      "\n",
      "What are your favourite places to eat at breakfast?\n",
      "\n",
      "Are you sure about your personal style?\n",
      "\n",
      "\n",
      "\n",
      "Q&A 11: \n",
      "What is the meaning of shalom in English?\n",
      "\n",
      "Shalom means \"taste\" which is the first thing to be thought of. It is one of the major expressions of the meaning of \"Shalam\". Meaning \"to be\n",
      "\n",
      "Q&A 12: \n",
      "Who was the author of the art of war?\n",
      "\n",
      "A wise man, who had no faith in God.\n",
      "\n",
      "It was written in the book of God, and it has inspired all men,\n",
      "\n",
      "And we all follow from it,\n",
      "\n",
      "Q&A 13: \n",
      "Largest state in the us by land mass? That's not to say the nation's population is the most populous that you have on the world maps. That's not to say they're a world class state. I think your population here is\n",
      "\n",
      "Q&A 14: \n",
      "Green algae is an example of which type of reproduction? What is required to produce offspring? Will food be enough to keep the plants in a stable health state.\n",
      "\n",
      "As far as food availability, we are in the process of having all the relevant\n",
      "\n",
      "Q&A 15: \n",
      "Vikram samvat calender is official in which country?\n",
      "\n",
      "Jalal A. Rajaram (State)\n",
      "\n",
      "What is the official currency of Pakistan?\n",
      "\n",
      "Pakistan uses one rupee (about 100 kal) per\n",
      "\n",
      "Q&A 16: \n",
      "Who is mostly responsible for writing the declaration of independence? I mean a bit of your name, but also: are you a writer, or in most cases a writer-in-waiting?\n",
      "\n",
      "This doesn't seem like the right question as\n",
      "\n",
      "Q&A 17: \n",
      "What us state forms the western boundary of montana?\n",
      "\n",
      "Nominal description, N:A, by means of the geological record, indicates Monta.\n",
      "\n",
      "We could also use the geographical coordinates for a region, but this wouldn't\n",
      "\n",
      "Q&A 18: \n",
      "Who plays ser davos in game of thrones?\n",
      "\n",
      "\n",
      "\"This is how I live. To have to live. It's the part of your mind that lets you know these things are true.\" Oh, don't call it that....\n",
      "\n",
      "Q&A 19: \n",
      "Who appoints the chair of the federal reserve system? If the chair of the national central bank is out in Washington, DC, what is his plan to reestablish the bank itself, for example—to move away from the idea of money transactions,\n",
      "\n",
      "Q&A 20: \n",
      "State the process that divides one nucleus into two genetically identical nuclei?\n",
      "\n",
      "It seems clear that we cannot rule this out, but the fact that the genome of the brain contains a nucleus with different regions from the genome of the body is a key\n",
      "\n",
      "Q&A 21: \n",
      "Who won the most mvp awards in the nba?\n",
      "\n",
      "1-1,\n",
      "\n",
      "2-0,\n",
      "\n",
      "3-1\n",
      "\n",
      "Top 4 winners of 2013 were:\n",
      "\n",
      "#1\n",
      "\n",
      "4-0,\n",
      "\n",
      "\n",
      "\n",
      "Q&A 22: \n",
      "What river is associated with the city of rome? It's the center of the city in every sense. As such, you have a number of cities such as Rome, Venice, Paris, Madrid and even in Madrid, one of those's most\n",
      "\n",
      "Q&A 23: \n",
      "Who is the first president to be impeached? Are there five or so days left in the year if that means the Senate impeached her? It wouldn't do,\" he said.\n",
      "\n",
      "There is one exception though, which could mean House Speaker\n",
      "\n",
      "Q&A 24: \n",
      "Who is the head of the department of homeland security 2017? Do you have any further questions?\".\n",
      "\n",
      "\"We are on track to hire a director within that time\", said the director of homeland security in reply to the question above.\n",
      "\n",
      "Last\n",
      "\n",
      "Q&A 25: \n",
      "What is the name given to the common currency to the european union? According to the ECB, it was the europrax.\n",
      "\n",
      "\n",
      "The euro can be exchanged for various european currencies.\n",
      "\n",
      "\n",
      "EUROPOLE\n",
      "\n",
      "Q&A 26: \n",
      "What was the name given to the common star wars? I suppose a lot of a lot of it is derived from other people's names, and I certainly think people should be able to say, well that's the only thing that makes sense after the\n",
      "\n",
      "Q&A 27: \n",
      "Do you have to have a gun permit to shoot at a range? Do you make your own ammo using your own ammo cartridges and then store it in your ammo box? Or do you pack up and leave when you leave?\n",
      "\n",
      "If you know\n",
      "\n",
      "Q&A 28: \n",
      "Who proposed evolution in 1859 as the basis of biological development?\n",
      "\n",
      "The origin of the universe was proposed in 1690 by Samuel Beckett in a Letter from the Naturalist, published in the Yearbook of the Church of the South, and\n",
      "\n",
      "Q&A 29: \n",
      "Nuclear power plant that blew up in russia? Then he did give them a look and asked them to go and check out an incinerator, which is radioactive. They said yes!\n",
      "\n",
      "So they went to one of those locations, he\n",
      "\n",
      "Q&A 30: \n",
      "Who played john connor in the original terminator?\n",
      "\n",
      "\n",
      "I did my very best to come up with this one at the end of the day. I think it was written for it like the rest of the game. There are no big spoilers\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline, set_seed\n",
    "\n",
    "generator = pipeline('text-generation', model='gpt2')\n",
    "set_seed(44)\n",
    "\n",
    "# 질문 목록\n",
    "questions = [\n",
    "    \"Who wrote the book the origin of species?\",\n",
    "    \"Who is the founder of the ubuntu project?\",\n",
    "    \"Who is the quarterback for the green bay packers?\",\n",
    "    \"Panda is a national animal of which country?\",\n",
    "    \"Who came up with the theory of relativity?\",\n",
    "    \"When was the first star wars film released?\",\n",
    "    \"What is the most common blood type in Sweden?\",\n",
    "    \"Who is regarded as the founder of psychoanalysis?\",\n",
    "    \"Who took the first steps on the moon in 1969?\",\n",
    "    \"Who is the largest supermarket chain in the uk?\",\n",
    "    \"What is the meaning of shalom in English?\",\n",
    "    \"Who was the author of the art of war?\",\n",
    "    \"Largest state in the us by land mass?\",\n",
    "    \"Green algae is an example of which type of reproduction?\",\n",
    "    \"Vikram samvat calender is official in which country?\",\n",
    "    \"Who is mostly responsible for writing the declaration of independence?\",\n",
    "    \"What us state forms the western boundary of montana?\",\n",
    "    \"Who plays ser davos in game of thrones?\",\n",
    "    \"Who appoints the chair of the federal reserve system?\",\n",
    "    \"State the process that divides one nucleus into two genetically identical nuclei?\",\n",
    "    \"Who won the most mvp awards in the nba?\",\n",
    "    \"What river is associated with the city of rome?\",\n",
    "    \"Who is the first president to be impeached?\",\n",
    "    \"Who is the head of the department of homeland security 2017?\",\n",
    "    \"What is the name given to the common currency to the european union?\",\n",
    "    \"What was the name given to the common star wars?\",\n",
    "    \"Do you have to have a gun permit to shoot at a range?\",\n",
    "    \"Who proposed evolution in 1859 as the basis of biological development?\",\n",
    "    \"Nuclear power plant that blew up in russia?\",\n",
    "    \"Who played john connor in the original terminator?\"\n",
    "]\n",
    "\n",
    "\n",
    "for i, question in enumerate(questions):\n",
    "    \n",
    "    answer = generator(question, max_length=50, truncation=True, num_return_sequences=1, pad_token_id=50256)[0]['generated_text']\n",
    "    print(f\"Q&A {i+1}: \\n{answer}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from transformers import pipeline, set_seed\n",
    "\n",
    "generator = pipeline('text-generation', model='gpt2-large')\n",
    "set_seed(22)\n",
    "prompt = \"Aaron loves mint chocolate cake, but he requires that it be paired with mini chocolate chips, so I threw some of\\\n",
    "those in between the layers. I also had a few Peppermint Jo Jos on hand so I crushed them up and threw some of \\\n",
    "those in along with some crushed meringue cookies because, why not? It’s a total smorgasbord of minty chocolate \\\n",
    "chippy cookie crunchy goodness. I didn’t measure how much of each topping I used, but after I tasted the finished \\\n",
    "product, I wish I had added more. You can add anything you want- crushed candy canes, peppermint bark, etc. And \\\n",
    "don’t be afraid to use a heavy hand. Texture = good. If you don’t have 7-inch cake pans, you can get 3 shorter 8-inch layers out of this\"\n",
    "results = generator(prompt, max_length=300, truncation=True, num_return_sequences=5, pad_token_id=50256)\n",
    "\n",
    "\n",
    "for i, result in enumerate(results):\n",
    "    print(f\"Generated Text {i+1}: \\n{result['generated_text']}\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 3: Benchmarking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "180d9ad7406342b5b2b7f483552c6876",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/3.25G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import GPT2LMHeadModel, GPT2Tokenizer\n",
    "from datasets import load_dataset\n",
    "\n",
    "# Load tokenizer and model\n",
    "tokenizer = GPT2Tokenizer.from_pretrained('gpt2-large')\n",
    "model = GPT2LMHeadModel.from_pretrained('gpt2-large')\n",
    "model.eval()\n",
    "\n",
    "# Load LAMBADA dataset\n",
    "dataset = load_dataset('lambada', split='validation')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to calculate perplexity\n",
    "def calculate_perplexity(text, model, tokenizer):\n",
    "    with torch.no_grad():  # Ensure no gradients are calculated to save memory\n",
    "        inputs = tokenizer(text, return_tensors='pt')\n",
    "        outputs = model(**inputs, labels=inputs[\"input_ids\"])\n",
    "        loss = outputs.loss\n",
    "        return torch.exp(loss)\n",
    "\n",
    "# Calculate perplexity in batches to save memory\n",
    "def calculate_average_perplexity(dataset, model, tokenizer, batch_size=10):\n",
    "    total_perplexity = 0\n",
    "    for i in range(0, len(dataset), batch_size):\n",
    "        batch = dataset[i:i+batch_size]['text']\n",
    "        batch_perplexity = sum(calculate_perplexity(text, model, tokenizer) for text in batch)\n",
    "        total_perplexity += batch_perplexity\n",
    "    return total_perplexity / len(dataset)\n",
    "\n",
    "# Call the function and print average perplexity\n",
    "average_perplexity = calculate_average_perplexity(dataset, model, tokenizer)\n",
    "print('Average Perplexity:', average_perplexity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "working_kernel",
   "language": "python",
   "name": "workspace"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
